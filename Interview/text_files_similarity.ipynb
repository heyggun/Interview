{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cd1133e",
   "metadata": {},
   "source": [
    "    You have 1 million text files, each is a news article scraped from various news sites. Since news sites often report the same news, even the same articles, many of the files have content very similar to each other. Write a program to filter out these files so that the end result contains only files that are sufficiently different from each other in the language of your choice. You’re free to choose a metric to define the “similarity” of content between files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572234de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d490685f",
   "metadata": {},
   "source": [
    "    - 파일에서 텍스트를 읽고 전처리함. \n",
    "    특수 문자를 제거하고 텍스트를 소문자로 변환.\n",
    "    전처리된 텍스트를 scikit-learn 라이브러리의 TfidfVectorizer를 사용해\n",
    "    TF_IDF vector로 변환\n",
    "    \n",
    "    - similarity는 cosine-similarity 함수를 사용\n",
    "    TF-IDF vector간의 cosine similarity 행렬 계산(모든 article의 유사도 점수)\n",
    "    \n",
    "    - 유사도 임계값을 정의하고, 유사한 기사를 식별하기 위해 유사도 행렬 반복적으로 확인\n",
    "    - 두 기사 간의 유사도 점수가 임계값을 초과하면 그들을 유사하다고 간주하고 그 중 하나만 고유하다고 표시\n",
    "    \n",
    "    - 고유한 파일의 인덱스 목록을 출력함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef3de4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984db0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_articles(filePath):\n",
    "    files = os.listdir(filePath)\n",
    "    num_files = len(files)\n",
    "    texts = []\n",
    "    for file in files:\n",
    "        with open(os.path.join(filePath, file), 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            text= preprocess_text(text)\n",
    "            texts.append(text)\n",
    "            \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    \n",
    "    # cacluate cosine similarity matrix\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    # filter out similar articles\n",
    "    unique_files = []\n",
    "    similary_threshold = 0.9\n",
    "    \n",
    "    for i in range(num_files):\n",
    "        if i not in unique_fiels:\n",
    "            unique_files.append(i)\n",
    "            for j in range(i+1, num_files):\n",
    "                if similarity_matrix[i, j] >= similar_threshold:\n",
    "                    unique_files.append(j)\n",
    "    \n",
    "    print(f\" Total files : {num_files}\")\n",
    "    print(f\" unique files : {len(unique_files)}\")\n",
    "    \n",
    "    for file_idx in unique_files:\n",
    "        print(files[file_idx])    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9eb3f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub('[^a-zA-Z0-9]+',' ',text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a13d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
